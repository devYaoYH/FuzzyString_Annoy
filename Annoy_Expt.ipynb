{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import time\n",
    "import chars2vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textdistance import levenshtein\n",
    "from annoy import AnnoyIndex\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for timing\n",
    "def debug_time(msg, init):\n",
    "    print(f\"{msg} [{(time.time()-init)*1000:.3f}ms]\", file=sys.stderr, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Constants\n",
    "NAME_MAXLENGTH = 20\n",
    "VEC_DIMS = 20 # actually |vec| = VEC_DIMS*k (for some variable k, see function <string2vec>)\n",
    "NUM_SIMILAR_RESULTS = 20 # get 20 most similar results by default\n",
    "\n",
    "CYCLE_INPUT_STRING = True  # Should we wrap-around strings if they are shorter than NAME_MAXLENGTH?\n",
    "                           # I think produces better results to 'control' for differences in string length\n",
    "\n",
    "# Permissible Distance Metrics\n",
    "ANNOY_DISTANCE_METRICS = [\"angular\", \"euclidean\", \"manhattan\", \"hamming\", \"dot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up 100 dimensional pre-trained chars2vec model\n",
    "c2v_model = chars2vec.load_model('eng_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract out 'License Name' column from dataset\n",
    "dataset = \"list-of-nea-licensed-eating-establishments.csv\"\n",
    "df = pd.read_csv(dataset)\n",
    "df = df['licensee_name']\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         REPUBLIC HOTELS & RESORTS LIMITED\n",
      "2                         M.K. RAMA PTE LTD\n",
      "3             GRAND PARK PROPERTY PTE. LTD.\n",
      "4                  MILLENIA PRIVATE LIMITED\n",
      "6              BCH HOTEL INVESTMENT PTE LTD\n",
      "                        ...                \n",
      "36682     AINON BTE BADRI ( AINON BTE ALI )\n",
      "36683         SYED IBRAHIM BIN PEER MOHAMED\n",
      "36684                      SAITON BINTE ALI\n",
      "36685                     AMINAH BTE K OMAR\n",
      "36686    AISHA BEGAM BINTE MOHAMED MUSTHAPA\n",
      "Name: licensee_name, Length: 22878, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitization function\n",
    "def sanitize_alpha(data, maxlen=NAME_MAXLENGTH):\n",
    "    orig_string = ''.join([c for c in data.lower() if c.isalpha()])\n",
    "    if (CYCLE_INPUT_STRING):\n",
    "        cyc_string = orig_string*(math.ceil(maxlen/len(orig_string)))\n",
    "        return cyc_string[:maxlen]\n",
    "    else:\n",
    "        return orig_string[:maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        republichotelsresort\n",
      "2        mkramapteltdmkramapt\n",
      "3        grandparkpropertypte\n",
      "4        milleniaprivatelimit\n",
      "6        bchhotelinvestmentpt\n",
      "                 ...         \n",
      "36682    ainonbtebadriainonbt\n",
      "36683    syedibrahimbinpeermo\n",
      "36684    saitonbintealisaiton\n",
      "36685    aminahbtekomaraminah\n",
      "36686    aishabegambintemoham\n",
      "Name: licensee_name, Length: 22878, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Clean up dataframe contents to only include ALPHABETICAL letters in lowercase (26 a-z)\n",
    "clean_df = df.map(sanitize_alpha)\n",
    "print(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_func = np.vectorize(len)\n",
    "maxlen_func(clean_df).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns alternate characters in given string\n",
    "def skipGram(string):\n",
    "    return string[::2]\n",
    "\n",
    "# encoding function\n",
    "def enc_sum(string_arr):\n",
    "    a = ord('a')\n",
    "    return int(sum([ord(c)-a for c in string_arr]))\n",
    "\n",
    "def enc_xor(string_arr):\n",
    "    a = ord('a')\n",
    "    return int(accumulate(string_arr, lambda accum,ele: accum^(ord(ele)-a)))\n",
    "\n",
    "# Specify some naive transform into vector representation for our data\n",
    "# 3 n-gram xor? of neighbors | 2,4 skip-gram xor? of neighbors\n",
    "# excess truncated | padded with 0-s\n",
    "# |vec| = dims*4 (for convenience)\n",
    "# also dims should >= maxlength of our data!\n",
    "def string2vec(string, enc_func, dims=VEC_DIMS, debug=False):\n",
    "    a = ord('a')\n",
    "    # original string\n",
    "    orig = [ord(c)-a for c in string][:min(len(string), dims)]\n",
    "    # 3 n-gram\n",
    "    ngram = [enc_func(string[i:i+3]) for i in range(min(len(string)-3, dims))]\n",
    "    # 2 skip-gram\n",
    "    skip2gram = [enc_func(skipGram(string[i:i+5])) for i in range(min(len(string)-5, dims))]\n",
    "    # 4 skip-gram\n",
    "    skip4gram = [enc_func(skipGram(string[i:i+9])) for i in range(min(len(string)-9, dims))]\n",
    "    if (debug):\n",
    "        print(ngram,skip2gram,skip4gram)\n",
    "    concat_data = (orig, ngram, skip2gram, skip4gram)\n",
    "#     concat_data = (ngram, skip2gram, skip4gram)\n",
    "#     concat_data = (orig, ngram)\n",
    "    vector = np.zeros(dims*len(concat_data))\n",
    "    for d, vec in enumerate(concat_data):\n",
    "        vector[dims*d:dims*d+len(vec)] = vec\n",
    "    return vector/np.linalg.norm(vector)\n",
    "#     return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 39, 36, 32, 20, 21, 17, 23, 40, 37, 34, 33, 46, 39, 39, 36, 49] [33, 35, 24, 33, 16, 27, 34, 20, 37, 36, 47, 26, 46, 36, 52] [48, 51, 50, 51, 46, 49, 62, 42, 72, 54, 82]\n",
      "[0.06099972 0.01435288 0.05382328 0.07176438 0.00358822 0.03947041\n",
      " 0.02870575 0.00717644 0.02511753 0.05023507 0.06817616 0.01435288\n",
      " 0.03947041 0.06458794 0.06099972 0.01435288 0.06458794 0.05023507\n",
      " 0.06099972 0.06817616 0.12917588 0.13994054 0.12917588 0.11482301\n",
      " 0.07176438 0.0753526  0.06099972 0.08252904 0.14352876 0.1327641\n",
      " 0.12199945 0.11841123 0.16505807 0.13994054 0.13994054 0.12917588\n",
      " 0.17582273 0.         0.         0.         0.11841123 0.12558766\n",
      " 0.08611726 0.11841123 0.0574115  0.09688191 0.12199945 0.07176438\n",
      " 0.1327641  0.12917588 0.16864629 0.09329369 0.16505807 0.12917588\n",
      " 0.18658739 0.         0.         0.         0.         0.\n",
      " 0.17223451 0.18299917 0.17941095 0.18299917 0.16505807 0.17582273\n",
      " 0.22246958 0.1507052  0.25835177 0.19376382 0.29423396 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(string2vec(\"republichotelsresort\", enc_sum, dims=VEC_DIMS, debug=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [0.06099972265241056, 0.014352875918214249, 0....\n",
      "2        [0.045912690759057614, 0.03826057563254801, 0....\n",
      "3        [0.018799819439045722, 0.053266155077296214, 0...\n",
      "4        [0.04675529712325957, 0.031170198082173046, 0....\n",
      "6        [0.0034414692207825072, 0.0068829384415650145,...\n",
      "                               ...                        \n",
      "36682    [0.0, 0.03999000374843818, 0.06498375609121206...\n",
      "36683    [0.08407819170887931, 0.1121042556118391, 0.01...\n",
      "36684    [0.07300204093126623, 0.0, 0.03244535152500721...\n",
      "36685    [0.0, 0.0544813303849538, 0.036320886923302535...\n",
      "36686    [0.0, 0.042171903025219545, 0.0948867818067439...\n",
      "Name: licensee_name, Length: 22878, dtype: object\n",
      "Encoding 22878 vectors: 1419.08813ms | avg: 0.06203ms\n"
     ]
    }
   ],
   "source": [
    "def string2vec_encSum(string):\n",
    "    return string2vec(string, enc_sum, dims=VEC_DIMS)\n",
    "enc_time = time.time()\n",
    "vec_df = clean_df.map(string2vec_encSum)\n",
    "enc_time = time.time() - enc_time\n",
    "print(vec_df)\n",
    "print(f\"Encoding {len(vec_df)} vectors: {enc_time*1000:.5f}ms | avg: {enc_time*1000/len(vec_df):.5f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.1368988e-01  3.8920587e-01  5.8130384e-03 ...  2.4472086e-01\n",
      "   4.0191626e-03  6.0844743e-01]\n",
      " [-1.0226086e-01  1.8165192e-01 -6.6250682e-01 ... -3.3742964e-01\n",
      "   5.3404528e-03  9.3769652e-01]\n",
      " [-4.6932191e-01  3.5536280e-01 -4.3260887e-01 ...  2.5469857e-01\n",
      "   1.9182866e-02  8.5552245e-01]\n",
      " ...\n",
      " [-7.2969013e-01  7.0039731e-01 -5.3937656e-01 ...  5.3412195e-02\n",
      "   2.1636357e-04  6.3521457e-01]\n",
      " [-2.1015666e-01  5.8237005e-02 -6.2032503e-01 ... -4.8170123e-01\n",
      "   5.5862684e-04  9.0191376e-01]\n",
      " [-1.4618242e-01  7.1757622e-02 -5.9894139e-01 ... -4.3950951e-01\n",
      "   1.2857503e-03  8.2262570e-01]]\n",
      "Encoding 22878 vectors: 5372.79081ms | avg: 0.23485ms\n"
     ]
    }
   ],
   "source": [
    "# More sophisticated vector embedding using chars2vec\n",
    "enc_time = time.time()\n",
    "vec_df = c2v_model.vectorize_words(list(clean_df))\n",
    "enc_time = time.time() - enc_time\n",
    "print(vec_df)\n",
    "print(f\"Encoding {len(vec_df)} vectors: {enc_time*1000:.5f}ms | avg: {enc_time*1000/len(vec_df):.5f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper Class for Annoy Trees\n",
    "class AnnoyTree(object):\n",
    "    def __init__(self, dims, wordlist, vectorlist, distance=\"euclidean\"):\n",
    "        self.model = None\n",
    "        self.distance_metric = distance\n",
    "        self.dims = dims\n",
    "        self.wordlist = wordlist[:]\n",
    "        self.vectors = vectorlist[:]\n",
    "        if (self.distance_metric not in ANNOY_DISTANCE_METRICS):\n",
    "            print(f\"ERROR!! Distance metric specified: {self.distance_metric} NOT FOUND\")\n",
    "    \n",
    "    # Trees control how many index trees are generated\n",
    "    # larger => more accurate, larger index file size\n",
    "    def build(self, output_fname, trees=10):\n",
    "        b_time = time.time()\n",
    "        self.model = AnnoyIndex(self.dims, self.distance_metric)\n",
    "        for i, word in enumerate(self.wordlist):\n",
    "            self.model.add_item(i, self.vectors[i])\n",
    "        self.model.build(trees)\n",
    "        debug_time(\"Model built in time\", b_time)\n",
    "        self.model.save(output_fname)\n",
    "        \n",
    "    # Extract model from saved index file\n",
    "    def load(self, input_fname):\n",
    "        self.model = AnnoyIndex(self.dims, self.distance_metric)\n",
    "        self.model.load(input_fname)\n",
    "        \n",
    "    # Interact with a built model\n",
    "    def query(self, q_vec, search_k=None, num_results=NUM_SIMILAR_RESULTS):\n",
    "        if (self.model is None):\n",
    "            print(\"Error: Model is not yet build or loaded!\")\n",
    "            return None\n",
    "        q_time = time.time()\n",
    "        if (search_k is not None):\n",
    "            neighbor_idx, dist = self.model.get_nns_by_vector(q_vec, num_results, search_k=search_k, include_distances=True)\n",
    "        else:\n",
    "            neighbor_idx, dist = self.model.get_nns_by_vector(q_vec, num_results, include_distances=True)\n",
    "        debug_time(\"Query in time\", q_time)\n",
    "        neighbors = map(lambda i: self.wordlist[i], neighbor_idx)\n",
    "        return zip(neighbors, dist)\n",
    "    \n",
    "    # Brute-force search\n",
    "    def brute_force(self, q_vec, num_results=NUM_SIMILAR_RESULTS):\n",
    "        q_time = time.time()\n",
    "        neighbor_idx, dist = zip(*sorted([(i, distance.cosine(q_vec, v)) for i,v in enumerate(self.vectors)], key=lambda x: x[1])[:num_results])\n",
    "        debug_time(\"Brute-Force in time\", q_time)\n",
    "        neighbors = map(lambda i: self.wordlist[i], neighbor_idx)\n",
    "        return zip(neighbors, dist)\n",
    "    \n",
    "    # Control using levenstein distance\n",
    "    def control_query(self, q, num_results=NUM_SIMILAR_RESULTS):\n",
    "        q_time = time.time()\n",
    "        results = sorted([(w, levenshtein(q, sanitize_alpha(w))) for w in self.wordlist], key=lambda x: x[1])[:num_results]\n",
    "        debug_time(\"Brute-Force with levenshtein\", q_time)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = AnnoyTree(len(vec_df[0]), list(df), list(vec_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model built in time [827.553ms]\n"
     ]
    }
   ],
   "source": [
    "test_tree.build(\"test_tree.ann\", trees=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.4280587e-01  9.3729451e-02 -8.3516635e-02  3.3228386e-03\n",
      "  9.2821896e-01 -5.1187521e-01  1.6161662e-01  3.7570089e-01\n",
      "  1.6440129e-01 -2.6656640e-01  1.0424998e-02 -1.6829653e-01\n",
      " -6.4724731e-01  1.8096562e-01 -7.7520795e-03  1.0755547e-01\n",
      " -2.6615241e-01  4.8587485e-03  6.5829790e-01  1.7199401e-02\n",
      " -3.8973264e-02  1.1518379e-04 -3.5060290e-02 -2.5793332e-01\n",
      " -8.0264896e-01  7.4051213e-01  5.5432284e-01  6.9274469e-03\n",
      "  9.9025995e-02  2.7460076e-02  1.6123313e-03  2.1976231e-01\n",
      "  4.5882529e-01 -2.0103514e-01  6.2030144e-02 -1.8514501e-01\n",
      "  7.2602725e-01 -3.5894036e-01  1.4303601e-01 -5.5412084e-01\n",
      "  1.7371629e-01  1.3631743e-01  1.6446654e-01  2.7124006e-01\n",
      " -6.7972660e-02  6.5722942e-01 -1.3679255e-02  1.4928398e-02\n",
      " -5.8605385e-01  1.8562210e-01  8.0269173e-02  1.2528962e-04\n",
      "  6.5358478e-01 -9.1295891e-02 -8.9641708e-01 -2.4489200e-02\n",
      "  8.7145464e-03 -2.2659227e-01  4.3999436e-01 -1.2071882e-03\n",
      " -5.3521049e-01  1.4459050e-01 -9.2551613e-01 -1.7982474e-01\n",
      " -7.1112216e-01 -2.5724316e-01 -1.3841062e-02 -6.2409425e-01\n",
      "  1.7336380e-02 -6.7360687e-01  1.1013595e-01 -8.0559608e-03\n",
      " -4.4128742e-02 -8.0214274e-01 -4.1134945e-01 -5.8160472e-01\n",
      "  6.4633286e-01  4.1374987e-01 -2.3217467e-04  7.8736776e-01\n",
      "  9.6884958e-04 -9.8511425e-04 -2.8830710e-01  1.5969180e-01\n",
      "  1.5752893e-03  5.1567112e-03  5.4528451e-01 -1.0286488e-01\n",
      " -6.0895556e-01 -4.2541876e-02  6.0782112e-02  8.9675590e-02\n",
      "  4.8800969e-01 -3.0521406e-03 -4.5127326e-01 -4.5513493e-01\n",
      " -7.3944211e-02  1.6123536e-01  1.2012766e-03  1.6468130e-01]\n"
     ]
    }
   ],
   "source": [
    "q_vec = c2v_model.vectorize_words([sanitize_alpha(\"tan chee hoon\")])[0]\n",
    "print(q_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query in time [2.227ms]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: TAN CHEE HOON | Distance: 0.00000\n",
      "Name: TAN CHEE HONG | Distance: 0.93064\n",
      "Name: TAN HEE CHONG | Distance: 1.17114\n",
      "Name: TAN CHEE YONG | Distance: 1.21273\n",
      "Name: CHEN CHEE HUONG | Distance: 1.34736\n",
      "Name: TAN WHEE HONG | Distance: 1.35105\n",
      "Name: TAN PECK HOON | Distance: 1.35883\n",
      "Name: OON CHEE WAH | Distance: 1.41322\n",
      "Name: HON WEI TECK | Distance: 1.41708\n",
      "Name: NEO CHIN CHER | Distance: 1.42421\n",
      "Name: TAN CHEW CHEONG | Distance: 1.42911\n",
      "Name: CHEN HONG | Distance: 1.45018\n",
      "Name: CHEE KIAT HOE (XU JIEHE) | Distance: 1.45298\n",
      "Name: CHEN CHEOW HIN | Distance: 1.46639\n",
      "Name: TING PECK CHOR | Distance: 1.47220\n",
      "Name: CHEW CHOR HIANG | Distance: 1.50341\n",
      "Name: CHENG KWOK THIN | Distance: 1.51361\n",
      "Name: CHEONG CHIEW YOON | Distance: 1.51814\n",
      "Name: CHEO CHEANG ZHENG | Distance: 1.52094\n",
      "Name: ANG HWEE CHOO | Distance: 1.53901\n"
     ]
    }
   ],
   "source": [
    "result = test_tree.query(q_vec)\n",
    "for name, dist in result:\n",
    "    print(f\"Name: {name} | Distance: {dist:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenient Helper function for quering tree\n",
    "def query_tree(query_string, annoy_tree):\n",
    "    # encode query\n",
    "#     q_vec = string2vec_encSum(sanitize_alpha(query_string))\n",
    "    q_vec = c2v_model.vectorize_words([sanitize_alpha(query_string)])[0]\n",
    "    result = annoy_tree.query(q_vec, search_k=10000)\n",
    "    for name, dist in result:\n",
    "        print(f\"Name: {name} | Distance: {dist:.5f}\")\n",
    "    print(\"Brute-Forced Results:\")\n",
    "    result = annoy_tree.brute_force(q_vec)\n",
    "    for name, dist in result:\n",
    "        print(f\"Name: {name} | Distance: {dist:.5f}\")\n",
    "    print(\"Control test with Levenshtein distance:\")\n",
    "    result = annoy_tree.control_query(sanitize_alpha(query_string))\n",
    "    for name, dist in result:\n",
    "        print(f\"Name: {name} | Distance: {dist:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query in time [2.226ms]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: SREE LEKHA (S) PTE. LTD. | Distance: 1.69012\n",
      "Name: HE-BREW COFFEE HOUSE PTE. LTD. | Distance: 1.82248\n",
      "Name: EVERLITE PTE LTD | Distance: 1.83670\n",
      "Name: SRI VEERA'S CURRY RESTAURANT PTE. LTD. | Distance: 1.85700\n",
      "Name: VERRE PTE. LTD. | Distance: 1.87220\n",
      "Name: SOLACE ENTERPRISE PTE LTD | Distance: 1.88055\n",
      "Name: KER ENG HOE | Distance: 1.88564\n",
      "Name: OVER EASY PTE. LTD. | Distance: 1.91238\n",
      "Name: EXPERIENCE PROJECT SG PTE. LTD. | Distance: 1.91520\n",
      "Name: PERFECT 12 PTE. LTD. | Distance: 1.91841\n",
      "Name: NG POR KEE | Distance: 1.91844\n",
      "Name: ROSWELL ENTERPRISE PTE LTD | Distance: 1.92400\n",
      "Name: ELETEX ENTERPRISES PTE. LTD. | Distance: 1.97764\n",
      "Name: SELETAR SEAFOOD CENTRE PTE LTD | Distance: 1.98097\n",
      "Name: HONEYWELL AEROSPACE SINGAPORE PTE. LTD. | Distance: 1.98386\n",
      "Name: PNG TECK SER | Distance: 1.99235\n",
      "Name: SHELL EASTERN PETROLEUM (PTE) LTD | Distance: 1.99751\n",
      "Name: SPICE CORNER LLP | Distance: 1.99942\n",
      "Name: TAY SWEE KEONG | Distance: 2.01291\n",
      "Name: LEE GEOK CHOO | Distance: 2.01347\n",
      "Brute-Forced Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Brute-Force in time [1087.327ms]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: SREE LEKHA (S) PTE. LTD. | Distance: 0.10455\n",
      "Name: EXPERIENCE PROJECT SG PTE. LTD. | Distance: 0.10461\n",
      "Name: ROSWELL ENTERPRISE PTE LTD | Distance: 0.10669\n",
      "Name: VERRE PTE. LTD. | Distance: 0.10723\n",
      "Name: SOLACE ENTERPRISE PTE LTD | Distance: 0.11023\n",
      "Name: SRI VEERA'S CURRY RESTAURANT PTE. LTD. | Distance: 0.11052\n",
      "Name: HE-BREW COFFEE HOUSE PTE. LTD. | Distance: 0.11074\n",
      "Name: EVERLITE PTE LTD | Distance: 0.11364\n",
      "Name: ELETEX ENTERPRISES PTE. LTD. | Distance: 0.11400\n",
      "Name: SPICE CORNER LLP | Distance: 0.11410\n",
      "Name: HONEYWELL AEROSPACE SINGAPORE PTE. LTD. | Distance: 0.11928\n",
      "Name: NG POR KEE | Distance: 0.12231\n",
      "Name: KER ENG HOE | Distance: 0.12788\n",
      "Name: OVER EASY PTE. LTD. | Distance: 0.12896\n",
      "Name: PERFECT 12 PTE. LTD. | Distance: 0.12911\n",
      "Name: BEVERAGE 33 PTE.LTD. | Distance: 0.13230\n",
      "Name: KA FENG ENTERPRISE PTE. LTD. | Distance: 0.13257\n",
      "Name: EXTREMERS ADVENTURE PTE LTD | Distance: 0.13372\n",
      "Name: LEE GEOK CHOO | Distance: 0.13495\n",
      "Name: GERRES PTE. LTD. | Distance: 0.13506\n",
      "Control test with Levenshtein distance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Brute-Force with levenshtein [23002.286ms]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: REPUBLIC HOTELS & RESORTS LIMITED | Distance: 5.00000\n",
      "Name: FURAMA HOTEL SINGAPORE PTE LTD? | Distance: 12.00000\n",
      "Name: BAY HOTEL & RESORT PTE. LTD. | Distance: 12.00000\n",
      "Name: REBECCA LOW SIEW YONG | Distance: 12.00000\n",
      "Name: AMARA HOTEL PROPERTIES PTE LTD? | Distance: 13.00000\n",
      "Name: RC HOTELS (PTE.) LTD | Distance: 13.00000\n",
      "Name: ROYAL CATERING SERVICES PTE LTD | Distance: 13.00000\n",
      "Name: LEGACY HOTEL PTE LTD | Distance: 13.00000\n",
      "Name: AVANT HOTELS (SINGAPORE) PTE LTD? | Distance: 13.00000\n",
      "Name: HARILELA HOTELS (SINGAPORE) PTE LTD? | Distance: 13.00000\n",
      "Name: Republic of Singapore Yacht Club | Distance: 13.00000\n",
      "Name: MEI JIA CHINESE RESTAURANT PTE LTD | Distance: 13.00000\n",
      "Name: STRAND HOTEL PTE LTD | Distance: 13.00000\n",
      "Name: RESTRANG PTE. LTD | Distance: 13.00000\n",
      "Name: TEXAS CHICKEN RESTAURANT PTE. LTD. | Distance: 13.00000\n",
      "Name: ES KOH PTE. LTD. | Distance: 13.00000\n",
      "Name: SILOSO BEACH RESORT PTE. LTD. | Distance: 13.00000\n",
      "Name: RAINTR33 HOTEL PTE. LTD. | Distance: 13.00000\n",
      "Name: ROXY HOTELS PTE. LTD. | Distance: 13.00000\n",
      "Name: Republic Polytechnic | Distance: 13.00000\n"
     ]
    }
   ],
   "source": [
    "query_tree(\"repblc hotels resors\", test_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04829701940586584\n"
     ]
    }
   ],
   "source": [
    "q1_vec = string2vec_encSum(sanitize_alpha(\"repblc hotels resors\"))\n",
    "q2_vec = string2vec_encSum(sanitize_alpha(\"REPUBLIC HOTELS & RESORTS LIMITED\"))\n",
    "print(distance.cosine(q1_vec, q2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20901548862457275\n"
     ]
    }
   ],
   "source": [
    "q1a_vec = c2v_model.vectorize_words([sanitize_alpha(\"repblc hotels resors\")])[0]\n",
    "q2a_vec = c2v_model.vectorize_words([sanitize_alpha(\"REPUBLIC HOTELS & RESORTS LIMITED\")])[0]\n",
    "print(distance.cosine(q1a_vec, q2a_vec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
